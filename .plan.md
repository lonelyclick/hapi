# Recall 提速方案：LangChain 混合检索

## 目标
将 `memoryRecall` 从纯 Agent SDK 多轮模式（10+ 轮，30-60 秒）改为 LangChain 混合检索模式（2 轮 LLM，3-5 秒）。

`memoryRemember` 保持 Agent SDK 不变。

## 方案

### 流程
1. **LLM 关键词扩展**：用户输入 → LangChain ChatModel → 生成 5-8 个中英文搜索关键词（structured output）
2. **ripgrep 多关键词搜索**：复用现有 `searchByRipgrep`，多关键词并行搜索
3. **读取匹配文件完整内容**：去重文件列表，读取完整 markdown 内容
4. **LLM 总结回答**：把文件内容 + 用户原始问题 → LangChain ChatModel → 结构化回答（含来源标注）

### 文件改动

#### 1. 安装依赖
```bash
cd /home/guang/happy/yoho-memory
bun add @langchain/core @langchain/openai
```
- `@langchain/core`：基础抽象（ChatModel, PromptTemplate, StructuredOutput）
- `@langchain/openai`：OpenAI 兼容格式调 LiteLLM（LiteLLM 是 OpenAI API 兼容的）

#### 2. 新建 `src/core/recall-chain.ts`
LangChain recall 实现：
- `createRecallChain(config)` 工厂函数
- 步骤 1：`ChatPromptTemplate` + `withStructuredOutput` → 关键词列表
- 步骤 2：调现有 `searchByRipgrep` 多关键词搜索
- 步骤 3：读文件，拼接上下文
- 步骤 4：`ChatPromptTemplate` → 总结回答
- LLM 实例：`ChatOpenAI({ baseURL: 'http://localhost:4000', apiKey: LITELLM_KEY, model: 'claude-haiku-4-5-20251001' })`

#### 3. 修改 `src/tools/recall.ts`
- 从 `agentRecall` 改为调用 `recallWithChain`
- 返回格式不变：`{ answer, turns: 2, durationMs }`

#### 4. 不动的文件
- `src/core/agent.ts` — remember 继续用，不改
- `src/mcp/server.ts` — 接口不变
- `src/http/routes/memory.ts` — 接口不变
- `src/tools/remember.ts` — 不改

### 关键词扩展 prompt 示例
```
你是搜索关键词生成器。根据用户的问题，生成 5-8 个搜索关键词用于 ripgrep 全文搜索。
要求：
- 包含中文和英文关键词
- 包含同义词、缩写、技术术语
- 每个关键词独立，不要组合短语
输出 JSON: { keywords: string[] }
```

### 总结 prompt 示例
```
你是 Yoho 记忆系统检索助手。根据以下记忆文件内容回答用户的问题。
规则：
- 只返回记忆中实际存在的信息，不要编造
- 标注来源文件路径
- 如果没找到相关内容，说"未找到相关记忆"
```

## 预期效果
- 速度：30-60 秒 → 3-5 秒（~10x 提升）
- 准确度：~90-95% 保留（关键词扩展弥补语义差距）
- 依赖：新增 @langchain/core + @langchain/openai
